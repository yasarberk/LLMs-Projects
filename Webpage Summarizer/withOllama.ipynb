{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d10e4c3-56b2-4701-a600-1b4dcf39e38d",
   "metadata": {},
   "source": [
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907f651-25a7-45d9-a95e-d82d5466e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242bfc84-1672-4ed2-b431-6b1eb288788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a78e2-7d05-4e2b-9e06-f6602758f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c14cdb-1c42-4b2c-a203-1b299da11829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# A class to represent a Webpage\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f5514-fe5c-45a2-8899-1d1166ee56b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's check the one website for an example\n",
    "ex = Website(\"https://vg247.com\")\n",
    "print(ex.title)\n",
    "print(ex.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b1021-eb7e-4d05-b728-b0b07ffb245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our system prompt\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e1207-6a5a-4575-9c52-57e24534743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e666f1-c36d-450c-bde8-890053ddd1a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function check\n",
    "\n",
    "print(user_prompt_for(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36021e5a-710e-46a2-97e9-85e8df3b1788",
   "metadata": {},
   "source": [
    "# Let's ask to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593efb0a-8013-4bd0-9f80-fc787fa10f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416bfb7-d177-4d73-af46-e6d8049dcdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages_for(website),\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9adc5-bd0a-4b1b-9eff-94083c890d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"https://geekozmos.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe30de-a36b-453c-848c-0db0b1f498bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb26fb-470c-497c-aecf-dda9aa369a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://geekozmos.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb2093-d2f1-4308-838f-7e997e067e5a",
   "metadata": {},
   "source": [
    "# BONUS: Try with DeepSeek R1\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f03db-68f4-4df6-9a44-b448de8d974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96ad7b-f598-452d-9a50-d21b4fc68cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f43a03-09e2-483a-9a3d-65ddc04041e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://geekozmos.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
